Brain_Tumor_Detection CODE

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

# Then move kaggle.json into the folder where the API expects to find it.
!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json
!kaggle datasets download -d navoneel/brain-mri-images-for-brain-tumor-detection

import tensorflow as tf
from zipfile import ZipFile
import os,glob
import cv2
from tqdm._tqdm_notebook import tqdm_notebook as tqdm
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D
from keras.layers import BatchNormalization
from keras.layers import MaxPooling2D
from keras.layers import Flatten

from zipfile import ZipFile
file_name = "/content/brain-mri-images-for-brain-tumor-detection.zip"
with ZipFile(file_name,'r') as zip:
  zip.extractall()
  print('Done')

os.chdir('/content/yes')
X = []
y = []
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(224,224))
      X.append(img)
      y.append((i[0:1]))
      print(i[0:1])
os.chdir('/content/no')
for i in tqdm(os.listdir()):
      img = cv2.imread(i)
      img = cv2.resize(img,(224,224))
      X.append(img)
for i in range(1,99):
    y.append('N')
print(y)

%matplotlib inline
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 10))
for i in range(4):
    plt.subplot(1, 4, i+1)
    plt.imshow(X[i], cmap="gray")
    plt.axis('off')
plt.show()

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
print ("Shape of an image in X_train: ", X_train[0].shape)
print ("Shape of an image in X_test: ", X_test[0].shape)

le = preprocessing.LabelEncoder()
y_train = le.fit_transform(y_train)
y_test = le.fit_transform(y_test)
y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=2)
y_train = np.array(y_train)
X_train = np.array(X_train)
y_test = np.array(y_test)
X_test = np.array(X_test)

print("X_train Shape: ", X_train.shape)
print("X_test Shape: ", X_test.shape)
print("y_train Shape: ", y_train.shape)
print("y_test Shape: ", y_test.shape)

from keras.applications import vgg16


img_rows, img_cols = 224, 224


vgg = vgg16.VGG16(weights = 'imagenet',
                 include_top = False,
                 input_shape = (img_rows, img_cols, 3))

# Here we freeze the last 4 layers
# Layers are set to trainable as True by default
for layer in vgg.layers:
    layer.trainable = False

# Let's print our layers
for (i,layer) in enumerate(vgg.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)

def lw(bottom_model, num_classes):
    """creates the top or head of the model that will be
    placed ontop of the bottom layers"""

    top_model = bottom_model.output
    top_model = GlobalAveragePooling2D()(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(512,activation='relu')(top_model)
    top_model = Dense(num_classes,activation='softmax')(top_model)
    return top_model

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D
from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D

from keras.models import Model


num_classes = 2

FC_Head = lw(vgg, num_classes)

model = Model(inputs = vgg.input, outputs = FC_Head)

print(model.summary())

from tensorflow.keras.models import Model
model.compile(optimizer='adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])

history = model.fit(X_train,y_train,
                    epochs=5,
                    validation_data=(X_test,y_test),
                    verbose = 1,
                    initial_epoch=0)

import matplotlib.pyplot as plt
%matplotlib inline
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(len(acc))

plt.plot(epochs, acc, 'r', label='Training accuracy')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc=0)
plt.figure()
plt.show()

epochs = range(len(loss))

plt.plot(epochs, loss, 'r', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend(loc=0)
plt.figure()
plt.show()

import matplotlib.pyplot as plt
%matplotlib inline

# Mapping dictionary
mapping = {0: "NO", 1: "Yes"}

# Create a figure to display the images
fig = plt.figure(figsize=(20, 20))

# Loop through the first 5 images in the test set
for i in range(5):
    # Get the image and its corresponding label
    data = X_test[i]
    target = y_test[i]

    # Reshape the image to match the input shape of the model
    data = np.expand_dims(data, axis=0)

    # Get the model's prediction
    pred = model.predict(data)

    # Convert the prediction to a class label
    pred_class = np.argmax(pred, axis=1)[0]
    actual_class = np.argmax(target, axis=0)

    # Display the image along with the actual and predicted labels
    plt.subplot(5, 5, i + 1)
    plt.imshow(data[0])
    plt.title(f"Actual : {mapping[actual_class]} Prediction : {mapping[pred_class]}")
    plt.axis('off')

plt.show()

!pip install scikit-learn

from sklearn.metrics import f1_score

# Get predictions for the entire test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels
y_true_classes = np.argmax(y_test, axis=1)  # Convert true labels to class labels

# Calculate F1 score
f1 = f1_score(y_true_classes, y_pred_classes, average='binary')  # Use 'binary' for binary classification
print(f"F1 Score: {f1}")

from sklearn.metrics import accuracy_score

# Get predictions for the entire test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels
y_true_classes = np.argmax(y_test, axis=1)  # Convert true labels to class labels

# Calculate accuracy
accuracy = accuracy_score(y_true_classes, y_pred_classes)
print(f"Accuracy: {accuracy}")

from sklearn.metrics import precision_score, recall_score

# Get predictions for the entire test set
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convert predictions to class labels
y_true_classes = np.argmax(y_test, axis=1)  # Convert true labels to class labels

# Calculate precision and recall
precision = precision_score(y_true_classes, y_pred_classes, average='binary')  # Use 'binary' for binary classification
recall = recall_score(y_true_classes, y_pred_classes, average='binary')  # Use 'binary' for binary classification

print(f"Precision: {precision}")
print(f"Recall: {recall}")

import pandas as pd

# Save evaluation metrics to a CSV file
metrics = {
    'Accuracy': [accuracy],
    'Precision': [precision],
    'Recall': [recall],
    'F1 Score': [f1]
}

metrics_df = pd.DataFrame(metrics)
metrics_df.to_csv('evaluation_metrics.csv', index=False)

# Save predictions to a CSV file
predictions_df = pd.DataFrame({
    'Actual': y_true_classes,
    'Predicted': y_pred_classes
})

predictions_df.to_csv('predictions.csv', index=False)

from google.colab import files

# Download evaluation_metrics.csv
files.download('evaluation_metrics.csv')

# Download predictions.csv
files.download('predictions.csv')

from google.colab import drive
drive.mount('/content/drive')

# Save evaluation metrics to Google Drive
metrics_df.to_csv('/content/drive/My Drive/evaluation_metrics.csv', index=False)

# Save predictions to Google Drive
predictions_df.to_csv('/content/drive/My Drive/predictions.csv', index=False)

# Save training history
history_df = pd.DataFrame({
    'Epoch': range(len(acc)),
    'Training Accuracy': acc,
    'Validation Accuracy': val_acc,
    'Training Loss': loss,
    'Validation Loss': val_loss
})
history_df.to_csv('training_history.csv', index=False)

from google.colab import files
files.download('training_history.csv')

import pandas as pd
from sklearn.metrics import confusion_matrix

# Calculate confusion matrix
cm = confusion_matrix(y_true_classes, y_pred_classes)

# Convert to a DataFrame
cm_df = pd.DataFrame(cm, columns=["Predicted No", "Predicted Yes"], index=["Actual No", "Actual Yes"])

# Reshape the confusion matrix into a long format
cm_long = cm_df.stack().reset_index()
cm_long.columns = ["Actual", "Predicted", "Count"]

# Save to CSV
cm_long.to_csv('confusion_matrix_long.csv', index=False)

# Print the reshaped data
print(cm_long)

from google.colab import files
files.download('confusion_matrix_long.csv')